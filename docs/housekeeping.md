# Docs Housekeeping Proposal

## 0) Inputs
- Changelog: docs/brief.md (v2.0 feature set)
- Reviewed docs:
  - USER_JOURNEY.md
  - TECH_OVERVIEW.md
  - GOTCHAS.md

## 1) Change inventory (from changelog)
- Database backup/restore scripts: backup_db.sh, restore_db.sh, backups/.gitkeep created (V-1)
- List export/import endpoints: GET /api/lists/export, POST /api/lists/import (V-2)
- Auto-fetch toggle: auto_fetch_enabled setting in system_settings, UI toggle in Settings → Scheduling (V-3)
- Prompts management system: New Prompt model, PromptService, /api/prompts endpoints, Prompts tab in Settings UI (V-4)
- Prompts export/import: GET /api/prompts/export, POST /api/prompts/import (V-5)
- AI worthiness scoring: score_worthiness method in openai_client.py, algorithmic formula removed from scheduler.py (V-6)
- AI duplicate detection: detect_duplicate method in openai_client.py, TF-IDF algorithm replaced with AI prompts (V-7)
- Auto-seed prompts on startup: seed_prompts_if_empty function in main.py (V-22)

## 2) Proposed updates by document (delta patches)

### USER_JOURNEY.md
#### Proposed edits
- [H001] Add backup script usage — ADD — Heading: "Phase 0: System Configuration" — Anchor: "Before browsing posts, users can configure" — New text: "**0.6 Database Backup & Restore**\n**User Action:** Use command-line backup/restore scripts\n\n**What Users Experience:**\n- ✅ Run `./backup_db.sh` to create timestamped SQL backup in `./backups/` directory\n- ✅ Run `./restore_db.sh <backup_file.sql>` to restore from backup with confirmation prompt\n- ✅ Backups survive `docker-compose down -v` (stored outside volumes)\n- ✅ Scripts display backup size and success confirmation\n\n**UX Notes:**\n- Restore operation shows warning about data overwrite\n- Scripts require postgres container to be running"

- [H002] Update Settings tabs count — REPLACE — Heading: "### 0.1 Access Settings" — Anchor: "Settings page with 4 main tabs: Data Sources, Scheduling, Content Filtering, System Control" — New text: "Settings page with 5 main tabs: Data Sources, Scheduling, Content Filtering, System Control, Prompts"

- [H003] Add auto-fetch toggle to Scheduling — INSERT AFTER — Heading: "### 0.3 Control Scheduling" — Anchor: "See estimated API calls per hour" — New text: "- ✅ Toggle automatic fetching on/off (Settings → Scheduling → Enable Automatic Fetch)\n- ✅ See auto-fetch status (Enabled/Paused) in System Control tab"

- [H004] Add list export/import buttons — INSERT AFTER — Heading: "### 0.2 Manage Data Sources" — Anchor: "Color-coded status indicators (Green: recent fetch, Yellow: stale, Red: error)" — New text: "- ✅ Export all lists to JSON file with \"Export Lists\" button\n- ✅ Import lists from JSON file with \"Import Lists\" button (merge behavior)\n- ✅ Exported lists include list_id, list_name, enabled status, fetch_frequency"

- [H005] Add Prompts management section — ADD — Heading: "Phase 0: System Configuration" — Anchor: "Before browsing posts, users can configure" (after 0.5 Manual System Control) — New text: "### 0.6 Manage AI Prompts\n**User Action:** Click \"Prompts\" tab\n\n**What Users Experience:**\n- ✅ View all 6 AI prompts (Categorization, Title Generation, Summary Generation, Article Generation, Worthiness Scoring, Duplicate Detection)\n- ✅ Edit prompt text, model, temperature, max_tokens via modal dialog\n- ✅ Reset prompts to defaults with confirmation\n- ✅ Export all prompts to JSON file\n- ✅ Import prompts from JSON file (overwrites existing)\n- ✅ Changes take effect immediately (no restart required)\n- ✅ Character count for prompt text validation"

- [H006] Update API endpoints list — INSERT AFTER — Heading: "**Accessible Endpoints**" — Anchor: "POST /api/admin/resume-scheduler - Resume background jobs" — New text: "- `GET /api/lists/export` - Export lists to JSON\n- `POST /api/lists/import` - Import lists from JSON\n- `GET /api/prompts` - Get all prompts\n- `GET /api/prompts/{name}` - Get single prompt\n- `PUT /api/prompts/{name}` - Update prompt\n- `POST /api/prompts/{name}/reset` - Reset prompt to default\n- `GET /api/prompts/export` - Export prompts to JSON\n- `POST /api/prompts/import` - Import prompts from JSON"

- [H007] Update AI-generated elements — REPLACE — Heading: "**Worthiness Scores:**" — Anchor: "0.0 to 1.0 scale (higher = better quality)\n- Combines relevance, quality, recency\n- Threshold: 0.6 for Recommended view" — New text: "0.0 to 1.0 scale (higher = better quality)\n- Generated by AI prompt evaluating newsworthiness (v2.0: AI-based)\n- Falls back to algorithmic scoring (relevance 40%, quality 40%, recency 20%) if AI fails\n- Threshold: 0.6 for Recommended view\n- Editable prompt via Settings → Prompts tab"

#### Issues found
- Settings tabs description inconsistent: Phase 0 intro says "4 main tabs" but sections 0.1-0.5 only describe 4, should be 5 (missing Prompts)
- No mention of backup/restore scripts despite implementation
- Duplicate detection description doesn't reflect v2.0 AI-based approach (still implies algorithmic only)
- API endpoint list outdated (missing v2.0 endpoints)

### TECH_OVERVIEW.md
#### Proposed edits
- [H008] Add backup scripts section — ADD — Heading: "## Configuration Management" (before or as new top-level section) — Anchor: TBD: add new section — New text: "## Backup & Restore Scripts ✅\n\n**Location:** Root directory ([backup_db.sh](backup_db.sh), [restore_db.sh](restore_db.sh))\n\n**Technical Implementation:**\n\n### backup_db.sh ✅\n```bash\n#!/bin/bash\nset -e\n\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nBACKUP_DIR=\"./backups\"\nBACKUP_FILE=\"${BACKUP_DIR}/klaus_news_backup_${TIMESTAMP}.sql\"\n\nmkdir -p \"${BACKUP_DIR}\"\ndocker-compose exec -T postgres pg_dump -U postgres klaus_news > \"${BACKUP_FILE}\"\n```\n\n**How It Works:**\n- Uses `docker-compose exec -T` to run pg_dump inside postgres container\n- `-T` flag disables pseudo-TTY allocation (required for piping output)\n- Stores backups outside Docker volumes in `./backups/` directory\n- Timestamped filenames prevent overwrites\n- Backups survive `docker-compose down -v`\n\n### restore_db.sh ✅\n**How It Works:**\n- Validates backup file exists before proceeding\n- Prompts user for confirmation (shows warning about data overwrite)\n- Stops backend/frontend containers during restore (prevents connection conflicts)\n- Drops existing database and recreates from backup\n- Uses `docker-compose exec -T postgres psql` with input redirection\n- Restarts containers after successful restore\n\n**Technical Details:**\n- Requires postgres container to be running\n- Uses database credentials from .env file (via docker-compose)\n- Error handling with `set -e` (exit on any command failure)"

- [H009] Add Prompt model to database schema — INSERT AFTER — Heading: "### SystemSettings Table" — Anchor: "Updated by VARCHAR  -- Future: track who changed settings" — New text: "---\n\n### Prompts Table ✅\n\nStores AI prompt configurations for all OpenAI operations:\n\n```sql\nCREATE TABLE prompts (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(100) UNIQUE NOT NULL,  -- e.g., 'categorization', 'worthiness'\n    display_name VARCHAR(200) NOT NULL,  -- e.g., 'Post Categorization'\n    prompt_text TEXT NOT NULL,\n    model VARCHAR(50) NOT NULL DEFAULT 'gpt-4-turbo',\n    temperature FLOAT NOT NULL DEFAULT 0.5,\n    max_tokens INT NOT NULL DEFAULT 100,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Initial prompts (6 default configurations)\n-- Auto-seeded on first startup via seed_prompts_if_empty() in main.py\n```\n\n**Location:** [backend/app/models/prompt.py](backend/app/models/prompt.py)\n\n**Technical Implementation:**\n- SQLAlchemy ORM model with full field mapping\n- Unique constraint on `name` field prevents duplicates\n- All 6 prompts auto-seeded on application startup\n- Used by PromptService with caching (similar to SettingsService)"

- [H010] Add PromptService section — INSERT AFTER — Heading: "### Settings Service" — Anchor: "Cache hit rate: >95% in typical usage" — New text: "---\n\n### Prompt Service ✅\n\n**Location:** [backend/app/services/prompt_service.py](backend/app/services/prompt_service.py)\n\n**Technical Implementation:**\n\n```python\nclass PromptService:\n    \"\"\"Load prompts from DB with caching\"\"\"\n    _cache = {}  # Class-level cache\n    _cache_expiry = 300  # 5 minutes (prompts change infrequently)\n    _cache_timestamps = {}\n\n    def get_prompt(self, name: str) -> dict:\n        \"\"\"Get prompt configuration with caching\"\"\"\n        # Check if cached and not expired\n        if name in self._cache and self._is_cache_fresh(name):\n            return self._cache[name]\n\n        # Query database\n        prompt = db.query(Prompt).filter_by(name=name).first()\n        if not prompt:\n            return self._get_default_prompt(name)  # Fallback to hardcoded defaults\n\n        # Build config dict\n        config = {\n            'text': prompt.prompt_text,\n            'model': prompt.model,\n            'temperature': prompt.temperature,\n            'max_tokens': prompt.max_tokens\n        }\n\n        # Update cache\n        self._cache[name] = config\n        self._cache_timestamps[name] = time.time()\n\n        return config\n\n    def invalidate_cache(self, name: str = None):\n        \"\"\"Clear cache for prompt or all prompts\"\"\"\n        if name:\n            self._cache.pop(name, None)\n            self._cache_timestamps.pop(name, None)\n        else:\n            self._cache.clear()\n            self._cache_timestamps.clear()\n```\n\n**How It Works:**\n- 5-minute TTL (longer than SettingsService because prompts change less frequently)\n- Fallback to hardcoded defaults if database entry missing (safe degradation)\n- Cache invalidation called from PUT /api/prompts/{name} after updates\n- Used by OpenAI client for all AI operations\n\n**Usage in OpenAI Client:**\n```python\ndef score_worthiness(self, post_text: str, category: str) -> float:\n    prompt_svc = PromptService()\n    config = prompt_svc.get_prompt('worthiness')\n    prompt_text = config['text'].format(post_text=post_text, category=category)\n    response = openai.ChatCompletion.create(\n        model=config['model'],\n        temperature=config['temperature'],\n        max_tokens=config['max_tokens'],\n        messages=[{\"role\": \"user\", \"content\": prompt_text}]\n    )\n    # Parse and return score...\n```"

- [H011] Update OpenAI Client to include new methods — INSERT AFTER — Heading: "#### 3. `generate_article`" — Anchor: "Future: Could integrate web search or additional context" — New text: "#### 4. `score_worthiness(post_text: str, category: str)` ✅ (v2.0 NEW)\n\n**How It Works:**\n- Prompt: Evaluates newsworthiness for internal company newsletter\n- Criteria: Relevance (40%), Quality (40%), Timeliness (20%)\n- Model: GPT-4-turbo (configurable via PromptService)\n- Temperature: 0.3 (low for consistency)\n- Max tokens: 10\n- Returns: Float between 0.0 and 1.0\n- Error handling: Returns 0.5 (neutral score) if API fails or returns non-numeric\n\n**Technical Detail:** Replaces algorithmic scoring formula that was in scheduler.py\n\n**Fallback Strategy:**\n- If AI call fails, falls back to algorithmic calculation:\n  - `worthiness = 0.4 × relevance + 0.4 × quality + 0.2 × recency`\n  - Prevents ingestion from breaking due to API issues\n\n#### 5. `detect_duplicate(new_post_text: str, existing_post_text: str)` ✅ (v2.0 NEW)\n\n**How It Works:**\n- Prompt: Determines if two posts describe the same news story\n- Criteria: Same core event, same key entities, same fundamental message\n- Model: GPT-4-turbo (configurable via PromptService)\n- Temperature: 0.2 (very low for consistency)\n- Max tokens: 5\n- Returns: Boolean (True if duplicates, False if distinct)\n- Response format: \"YES\" or \"NO\"\n\n**Technical Detail:** Replaces pure TF-IDF cosine similarity approach\n\n**Hybrid Strategy:**\n- Layer 1: SHA-256 hash for exact duplicates (unchanged)\n- Layer 2: AI duplicate detection for semantic duplicates (new)\n- Layer 3: TF-IDF fallback if AI call fails (safety net)\n\n**Integration:**\n- Called during ingestion after SHA-256 check\n- Compares new post against up to 50 recent posts in same category\n- Caches results per post pair to avoid redundant calls"

- [H012] Update Duplicate Detection section — REPLACE — Heading: "### Duplicate Detection" — Anchor: "**Technical Details:**\n- TF-IDF captures semantic similarity, not just exact matches\n- Can detect rephrased tweets or similar topics\n- Higher threshold (0.85) = more conservative grouping" — New text: "**Technical Details (v2.0 Hybrid Approach):**\n- **Layer 1 (Exact):** SHA-256 hash matching (unchanged, fast)\n- **Layer 2 (Semantic):** AI-based duplicate detection via OpenAI\n  - Compares new post against up to 50 recent posts in same category\n  - Returns YES/NO based on semantic similarity\n  - Can detect rephrased tweets, same story with different wording\n- **Layer 3 (Fallback):** TF-IDF cosine similarity (threshold: 0.85)\n  - Used if AI call fails or times out\n  - Ensures ingestion never blocks due to API issues\n- **Optimization:** Only compares within same category (reduces API calls)\n- **Caching:** Post pair results cached per session (avoids redundant calls)"

- [H013] Update Scoring Algorithm section — REPLACE — Heading: "### Scoring Algorithm" — Anchor: "**Technical Rationale:**\n- Balances AI confidence (relevance) with objective metrics (quality, recency)\n- Sigmoid for length prevents harsh cliffs\n- Recency decay encourages fresh content\n- Threshold 0.6 used for \"Recommended\" filter" — New text: "**Technical Rationale (v2.0 AI-First Approach):**\n- **Primary:** AI-based scoring via OpenAI worthiness prompt\n  - Evaluates relevance, quality, timeliness holistically\n  - More nuanced than algorithmic formula\n  - Configurable via Settings → Prompts tab\n- **Fallback:** Algorithmic calculation if AI fails:\n  - Formula: `0.4 × relevance + 0.4 × quality + 0.2 × recency`\n  - Relevance: Uses categorization_score (AI confidence)\n  - Quality: Length score (sigmoid) + coherence (caps ratio, punctuation)\n  - Recency: Linear decay over 7 days\n- **Error Handling:** Default to 0.5 (neutral) if both AI and algorithm fail\n- Threshold 0.6 used for \"Recommended\" filter (unchanged)"

- [H014] Update system_settings section — INSERT AFTER — Heading: "-- Initial settings (8 default configuration values)" — Anchor: "('scheduler_paused', 'false', 'bool', 'Whether background scheduler is paused', 'system', NULL, NULL);" — New text: "('auto_fetch_enabled', 'true', 'bool', 'Enable/disable automatic post fetching', 'scheduling', NULL, NULL),"

- [H015] Add Prompts API endpoints — INSERT AFTER — Heading: "### Lists Management API" — Anchor: "**Technical Detail:** Makes actual X API call to validate list exists" — New text: "**✅ `GET /api/lists/export`** - FULLY IMPLEMENTED (v2.0)\n- Returns all lists as downloadable JSON file\n- Format: `{\"export_version\": \"2.0\", \"exported_at\": \"...\", \"lists\": [...]}`\n- **Location:** [backend/app/api/lists.py](backend/app/api/lists.py)\n\n**✅ `POST /api/lists/import`** - FULLY IMPLEMENTED (v2.0)\n- Accepts JSON file upload, validates schema, imports lists\n- Merge behavior: Updates existing list_id, adds new lists\n- Imported lists set to enabled: false by default (safety)\n- **Location:** [backend/app/api/lists.py](backend/app/api/lists.py)\n\n---\n\n### Prompts Management API (v2.0 NEW)\n\n**✅ `GET /api/prompts`** - FULLY IMPLEMENTED\n- Returns all 6 prompts with current values\n- Includes: name, display_name, prompt_text, model, temperature, max_tokens\n- **Location:** [backend/app/api/prompts.py](backend/app/api/prompts.py)\n\n**✅ `GET /api/prompts/{name}`** - FULLY IMPLEMENTED\n- Returns single prompt details by name (e.g., 'categorization', 'worthiness')\n- **Location:** [backend/app/api/prompts.py](backend/app/api/prompts.py)\n\n**✅ `PUT /api/prompts/{name}`** - FULLY IMPLEMENTED\n- Updates prompt configuration (text, model, temperature, max_tokens)\n- Invalidates PromptService cache\n- Changes take effect immediately (next API call uses new prompt)\n- **Location:** [backend/app/api/prompts.py](backend/app/api/prompts.py)\n\n**✅ `POST /api/prompts/{name}/reset`** - FULLY IMPLEMENTED\n- Resets prompt to hardcoded default from code\n- Shows confirmation dialog in UI\n- **Location:** [backend/app/api/prompts.py](backend/app/api/prompts.py)\n\n**✅ `GET /api/prompts/export`** - FULLY IMPLEMENTED\n- Returns all prompts as downloadable JSON file\n- Format: `{\"export_version\": \"2.0\", \"exported_at\": \"...\", \"prompts\": {\"categorization\": {...}, ...}}`\n- **Location:** [backend/app/api/prompts.py](backend/app/api/prompts.py)\n\n**✅ `POST /api/prompts/import`** - FULLY IMPLEMENTED\n- Accepts JSON file upload, validates schema, imports prompts\n- Overwrite behavior: Replaces all matching prompts\n- Partial import supported (only updates included prompts)\n- **Location:** [backend/app/api/prompts.py](backend/app/api/prompts.py)"

- [H016] Update frontend components list — INSERT AFTER — Heading: "#### **Settings.tsx**" — Anchor: "**Status:** Complete and fully functional" — New text: "---\n\n#### **Prompts.tsx** ✅ FULLY FUNCTIONAL (v2.0 NEW)\n**Location:** [frontend/src/pages/Prompts.tsx](frontend/src/pages/Prompts.tsx)\n\n**Technical Implementation:**\n- Table display of 6 AI prompts:\n  - Post Categorization\n  - Post Title Generation\n  - Post Summary Generation\n  - Article Generation\n  - Worthiness Scoring (new in v2.0)\n  - Duplicate Detection (new in v2.0)\n- Columns: Prompt Name, Model, Temperature, Max Tokens, Last Modified, Actions\n- Edit modal with:\n  - Prompt text textarea (10 rows, character count)\n  - Model dropdown (gpt-4-turbo, gpt-4, gpt-3.5-turbo)\n  - Temperature input (0.0-2.0, step 0.1)\n  - Max Tokens input (1-4000)\n  - Buttons: Save, Cancel, Reset to Default\n- Export/Import buttons (top-right corner)\n- Real-time validation and success/error toasts\n\n**What's Implemented:**\n- ✅ View all prompts with current configurations\n- ✅ Edit prompt text and parameters via modal\n- ✅ Reset individual prompt to default\n- ✅ Export all prompts to JSON\n- ✅ Import prompts from JSON (overwrites)\n- ✅ Character count for prompt text\n- ✅ Validation prevents empty prompts\n- ✅ Changes take effect immediately\n\n**Status:** Complete and fully functional"

- [H017] Update ingestion job to reflect v2.0 changes — INSERT AFTER — Heading: "**How It Works:**" (in ingest_posts_job section) — Anchor: "For each new post:\n     - Check if `post_id` already exists (skip if duplicate)\n     - Call `openai_client.categorize_post()` → get category + confidence\n     - Call `openai_client.generate_title_and_summary()` → get title + summary\n     - Calculate `worthiness_score` via scoring algorithm\n     - Compute `content_hash` via SHA-256\n     - Assign `group_id` via duplicate detection\n     - Insert to database as new Post record" — New text: "   - For each new post (v2.0 updated flow):\n     - Check if `post_id` already exists (skip if duplicate)\n     - Check `auto_fetch_enabled` setting; if false, skip ingestion and return early\n     - Call `openai_client.categorize_post()` → get category + confidence\n     - Call `openai_client.generate_title_and_summary()` → get title + summary\n     - Call `openai_client.score_worthiness(post_text, category)` → get AI worthiness score (v2.0 NEW)\n       - Falls back to algorithmic calculation if AI fails\n     - Compute `content_hash` via SHA-256\n     - Assign `group_id` via hybrid duplicate detection (v2.0 UPDATED):\n       1. Check SHA-256 hash for exact match\n       2. If no match, call `openai_client.detect_duplicate()` against recent posts (v2.0 NEW)\n       3. If AI fails, fall back to TF-IDF similarity\n     - Insert to database as new Post record"

#### Issues found
- Missing documentation for v2.0 features: backup scripts, prompts system, AI scoring/duplicate detection
- Database schema section missing Prompt model
- OpenAI Client section missing score_worthiness and detect_duplicate methods
- Duplicate detection description doesn't reflect hybrid approach (SHA-256 + AI + TF-IDF fallback)
- Scoring algorithm description doesn't reflect AI-first approach with fallback
- Settings API endpoints list missing prompts endpoints
- Frontend components list missing Prompts.tsx
- Ingestion flow description doesn't reflect v2.0 changes (AI scoring, AI duplicate detection, auto_fetch check)

### GOTCHAS.md
#### Proposed edits
- [H018] Add backup script gotchas — ADD — Heading: "## Database & Persistence" — Anchor: TBD: add new section (before "### No Migration System") — New text: "### Backup Script Dependencies\n**Issue:** backup_db.sh and restore_db.sh require postgres container to be running\n**Risk:** Medium (5/10)\n**Behavior:** Scripts fail with \"container not found\" if postgres container is stopped\n**Mitigation:** Check `docker-compose ps` before running scripts; scripts should validate container state\n\n### Restore Overwrites All Data\n**Issue:** restore_db.sh drops entire database and recreates from backup (destructive)\n**Risk:** High (8/10)\n**Behavior:** All data created since backup timestamp is permanently lost\n**Mitigation:** Confirmation prompt warns user; recommend creating fresh backup before restore\n\n### Backups Not Automatically Scheduled\n**Issue:** Daily backup cron job (setup_cron.sh) not configured by default\n**Risk:** Medium (6/10)\n**Behavior:** Users must manually run backup_db.sh or configure cron themselves\n**Mitigation:** Document cron setup in deployment playbook; provide setup_cron.sh script"

- [H019] Add prompt management gotchas — ADD — Heading: "## Settings & Configuration" — Anchor: TBD: add new section (after "### Threshold Changes Affecting Existing Posts") — New text: "### Invalid Prompts Breaking AI Operations\n**Issue:** Users can edit prompts to invalid or empty text, breaking AI functionality\n**Risk:** Critical (9/10)\n**Behavior:** Empty or malformed prompts cause OpenAI API errors, blocking ingestion/article generation\n**Mitigation:** UI validation prevents empty prompts; Reset to Default button available; fallback to hardcoded defaults if database entry missing\n\n### Prompt Changes Immediate Effect\n**Issue:** Prompt edits take effect immediately without preview or staging\n**Risk:** Medium (5/10)\n**Behavior:** Bad prompt can immediately affect all new posts ingested\n**Mitigation:** Export prompts before editing (manual versioning); Reset to Default available\n\n### No Prompt Change History\n**Issue:** Cannot view previous prompt versions or revert changes\n**Risk:** Medium (4/10)\n**Behavior:** If user edits prompt and forgets original, must reset to default (loses custom tuning)\n**Mitigation:** Recommend exporting prompts before major changes; implement audit log in future"

- [H020] Add AI cost gotchas — ADD — Heading: "## Known Limitations" — Anchor: TBD: add new section (before "- **Single-user assumption:**") — New text: "### v2.0 AI Cost Increase\n**Issue:** v2.0 features significantly increase OpenAI API costs (~$7/month → ~$20-70/month)\n**Risk:** High (7/10) - budget impact\n**Behavior:**\n- Worthiness scoring: +1 API call per post (~$0.60/month for 3000 posts)\n- Duplicate detection: +10-50 API calls per post (~$60/month for 3000 posts with 10 avg comparisons)\n- Total increase: ~$60/month without optimizations\n**Mitigation:**\n- Use gpt-3.5-turbo for duplicate detection (saves ~$45/month)\n- Reduce duplicate_check_limit from 50 to 20 (saves ~$24/month)\n- Only run duplicate check on high-worthiness posts (>0.7 threshold, saves ~$30-40/month)\n- With optimizations: estimated ~$20-25/month total\n\n### AI Rate Limits\n**Issue:** High post volume can hit OpenAI API rate limits (especially duplicate detection)\n**Risk:** Medium (6/10)\n**Behavior:** API returns 429 errors, ingestion slows or fails\n**Mitigation:** Duplicate detection has fallback to TF-IDF; implement exponential backoff; monitor rate limit headers"

- [H021] Update known limitations — DELETE — Heading: "## Known Limitations" — Anchor: "- **No backup/restore:** Settings export/import not implemented" — New text: ""

- [H022] Add prompt export/import to known limitations — REPLACE — Heading: "## Known Limitations" — Anchor: "- **No backup/restore:** Settings export/import not implemented" — New text: "- **Backup/restore for database:** ✅ Implemented (v2.0: backup_db.sh, restore_db.sh)\n- **Export/import for lists:** ✅ Implemented (v2.0: GET /api/lists/export, POST /api/lists/import)\n- **Export/import for prompts:** ✅ Implemented (v2.0: GET /api/prompts/export, POST /api/prompts/import)\n- **Settings export/import:** Not implemented (system_settings table export/import not available)"

- [H023] Update duplicate detection performance note — REPLACE — Heading: "### Duplicate Post Protection" — Anchor: "**Issue:** TF-IDF similarity scales O(n) with post count" — New text: "**Issue:** AI-based duplicate detection scales O(n) with post count and increases API costs\n**Risk:** Medium (5/10) - performance and cost concern\n**Behavior:** \n- Each new post compared against up to 50 recent posts (configurable via duplicate_check_limit)\n- 10-50 API calls per post in worst case\n- Slowdown and cost increase with high post volume\n**Mitigation:** \n- Limit comparison to 50 recent posts\n- Only compare within same category (reduces API calls)\n- Cache results per post pair\n- Fallback to TF-IDF if AI fails (performance safety net)\n- Archive posts older than 7 days to reduce comparison pool"

#### Issues found
- Missing gotchas for v2.0 features: backup scripts, prompts management, AI costs
- "No backup/restore" limitation is outdated (now implemented in v2.0)
- Duplicate detection gotcha doesn't reflect v2.0 AI-based approach
- No mention of AI rate limits or cost implications

## 3) Cross-doc consistency issues
- USER_JOURNEY.md says "4 main tabs" in Settings, should be "5 main tabs" (includes Prompts tab)
- TECH_OVERVIEW.md duplicate detection section describes pure TF-IDF approach, but v2.0 uses hybrid (SHA-256 + AI + TF-IDF fallback)
- TECH_OVERVIEW.md scoring section describes only algorithmic formula, but v2.0 uses AI-first with fallback
- GOTCHAS.md "No backup/restore" limitation contradicts implemented v2.0 features

## 4) Open questions (blockers)
None. All proposed changes are based on verified implementations documented in code_implementation_verification.md.

## 5) Minimal recommended edit order
1) USER_JOURNEY.md: Update Settings tabs count to 5 (H002) - quick fix, unblocks accuracy
2) USER_JOURNEY.md: Add Prompts management section (H005) - major new feature documentation
3) TECH_OVERVIEW.md: Add Prompt model to database schema (H009) - foundational documentation
4) TECH_OVERVIEW.md: Add PromptService section (H010) - architectural documentation
5) TECH_OVERVIEW.md: Update OpenAI Client with new methods (H011) - technical detail
6) TECH_OVERVIEW.md: Add Prompts API endpoints (H015) - API reference completeness
7) GOTCHAS.md: Add prompt management gotchas (H019) - safety documentation
8) GOTCHAS.md: Add AI cost gotchas (H020) - critical cost awareness
9) GOTCHAS.md: Update known limitations (H021, H022) - accuracy correction
10) USER_JOURNEY.md: Add backup script usage (H001) - operational documentation
11) TECH_OVERVIEW.md: Add backup scripts section (H008) - operational documentation
12) GOTCHAS.md: Add backup script gotchas (H018) - operational safety
13) All remaining updates in any order (minor corrections and completeness)
